{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import networks as nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "unet = nw.UNet(input_size=(256, 256, 3), num_classes=1)\n",
    "\n",
    "out = unet.call(tf.random.normal((1, 256, 256, 3)))  # Call the model with a random input to build the model\n",
    "print(out.shape) # Make sure the output shape is correct\n",
    "\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"Load an image, decode it, and resize to 256x256\"\"\"\n",
    "    img = tf.io.read_file(image_path)               # Read image\n",
    "    img = tf.image.decode_jpeg(img, channels=3)       # Decode as JPG (assuming JPG images)\n",
    "    img = tf.image.resize(img, (256, 256))           # Resize to target size\n",
    "    img = img / 255.0                               # Normalize to range [0, 1]\n",
    "    return img\n",
    "\n",
    "def load_mask(mask_path):\n",
    "    \"\"\"Load a mask, decode it, and resize to 256x256\"\"\"\n",
    "    mask = tf.io.read_file(mask_path)               # Read mask image\n",
    "    mask = tf.image.decode_png(mask, channels=1)     # Decode as PNG (assuming masks are single-channel)\n",
    "    mask = tf.image.resize(mask, (256, 256))         # Resize to target size\n",
    "    mask = mask / 255.0                             # Normalize to range [0, 1]\n",
    "    return mask\n",
    "\n",
    "def load_data(image_folder, mask_folder):\n",
    "    # Get image and mask file paths\n",
    "    image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder)]\n",
    "    mask_paths = [os.path.join(mask_folder, fname) for fname in os.listdir(mask_folder)]\n",
    "    \n",
    "    # Shuffle the paths (optional)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "\n",
    "    # Load images and masks\n",
    "    dataset = dataset.map(lambda x, y: (load_image(x), load_mask(y)))\n",
    "    \n",
    "    # Shuffle and batch the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=1000)  # Shuffle with buffer_size (adjust as needed)\n",
    "    dataset = dataset.batch(batch_size=16)  # Batch size for training (adjust as needed)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory paths\n",
    "image_folder = 'normalized_images'\n",
    "mask_folder = 'normalized_masks'\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = load_data(image_folder, mask_folder)\n",
    "\n",
    "# Check the dataset shapes (optional)\n",
    "for images, masks in train_dataset.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Mask batch shape:\", masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of GPUs available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "print(\"Is TensorFlow using GPU? \", tf.test.is_gpu_available())\n",
    "print(\"GPU Details: \", tf.config.experimental.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "unet.fit(train_dataset, epochs=5)  # Adjust the number of epochs as needed\n",
    "\n",
    "# Save the model\n",
    "unet.save('unet_model.keras')  # Save the model in native Keras format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory paths\n",
    "image_folder = 'test_normalized_images'\n",
    "mask_folder = 'test_normalized_masks'\n",
    "\n",
    "# Load the dataset\n",
    "test_dataset = load_data(image_folder, mask_folder)\n",
    "\n",
    "# Check the dataset shapes (optional)\n",
    "for images, masks in test_dataset.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Mask batch shape:\", masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('unet_model.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = loaded_model.evaluate(test_dataset)\n",
    "\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*accuracy))\n",
    "\n",
    "# Predict on a sample image\n",
    "sample_image = load_image('normalized_images/test.png')\n",
    "sample_image = tf.expand_dims(sample_image, 0)  # Add batch dimension\n",
    "prediction = loaded_model.predict(sample_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Lists to store true masks and predicted masks\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "# Iterate over the test dataset\n",
    "for image, mask in test_dataset:\n",
    "    preds = unet.predict(image)  # Get predicted mask\n",
    "    preds = (preds > 0.5).astype(np.uint8)  # Convert to binary mask using threshold 0.5\n",
    "\n",
    "    # Flatten the arrays for Jaccard computation\n",
    "    y_true_list.append(mask.numpy().flatten())\n",
    "    y_pred_list.append(preds.flatten())\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "y_true = np.concatenate(y_true_list)\n",
    "y_pred = np.concatenate(y_pred_list)\n",
    "\n",
    "\n",
    "# Compute Jaccard Index (IoU)\n",
    "jaccard = jaccard_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Jaccard Index (IoU): {jaccard:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Generate predictions on the test dataset\n",
    "y_true = []  # Ground truth masks (binary)\n",
    "y_scores = []  # Predicted probability maps\n",
    "\n",
    "for image, mask in test_dataset:  # Iterate over your dataset\n",
    "    preds = unet.predict(image)  # Get model predictions\n",
    "    y_true.append(mask.numpy().flatten())  # Flatten the ground truth\n",
    "    y_scores.append(preds.flatten())  # Flatten predictions\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "y_true = np.concatenate(y_true)\n",
    "y_scores = np.concatenate(y_scores)\n",
    "\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute Youden's J statistic to find the best threshold\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = _[optimal_idx]\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
